import os
from collections import defaultdict
import numpy as np
import random

import pandas as pd
from scipy.sparse import csr_matrix
from scipy.sparse import vstack

dir_path = os.path.dirname(os.path.realpath(__file__))



raw_dir = dir_path+'/../../data/raw/'
processed_dir = dir_path+'/../../data/processed/'

df = pd.read_csv(raw_dir+'sha256_family.csv')
malware = set(df['sha256'].values)

code_idx = 0
def code_l():
    global code_idx
    ret = code_idx
    code_idx = code_idx + 1
    return ret
code_map = defaultdict(code_l)

manifest_idx = 0
def manifest_l():
    global manifest_idx
    ret = manifest_idx
    manifest_idx = manifest_idx + 1
    return ret
manifest_map = defaultdict(manifest_l)

manifest_prefix = {
'activity':True,
'feature':True,
'intent':True,
'permission':True,
'provider':True,
'service_receiver':True
}

code_prefix = {
'real_permission':True,
'api_call':True,
'call':True,
'url':True
}

manifest_inputs = 185729 + 72 + 6379 + 3812 + 4513 + 33222
code_inputs = 310488 + 315 + 733 + 70
samples = 129013
num_mal = 5561
split = True

#Reduce the size of the data for downsample malware
if split:
    samples = samples - int(len(malware)*1)

entries = samples * 50
x_manifest_dat = np.zeros((entries,), dtype=np.int32)
x_manifest_row = np.zeros((entries,), dtype=np.int32)
x_manifest_col = np.zeros((entries,), dtype=np.int32)

x_code_dat = np.zeros((entries,), dtype=np.int32)
x_code_row = np.zeros((entries,), dtype=np.int32)
x_code_col = np.zeros((entries,), dtype=np.int32)

good_hashes = []
mal_hashes = []


if not split:
    y = np.zeros((samples,), dtype=np.int8)
    perm = np.random.permutation(samples)
else:
    entries = num_mal * 50
    x_manifest_dat_mal = np.zeros((entries,), dtype=np.int32)
    x_manifest_row_mal = np.zeros((entries,), dtype=np.int32)
    x_manifest_col_mal = np.zeros((entries,), dtype=np.int32)

    x_code_dat_mal = np.zeros((entries,), dtype=np.int32)
    x_code_row_mal = np.zeros((entries,), dtype=np.int32)
    x_code_col_mal = np.zeros((entries,), dtype=np.int32)

print ('Loading data')

indir = raw_dir+'feature_vectors'

x_i = {
    'x_m': 0,
    'x_c': 0,
    'i': 0
}

x_i_m = {
    'x_m': 0,
    'x_c': 0,
    'i': 0
}

num = 0
num_mal = 0
for root, dirs, filenames in os.walk(indir):
    for fname in filenames:
        sha256 = fname
        
        isMalware = sha256 in malware
        
        if isMalware:
            num_mal = num_mal + 1
            mal_hashes.append(sha256)
        else:
            good_hashes.append(sha256)
        
        if split:            
            if isMalware:
                x_m_d = x_manifest_dat_mal
                x_m_r = x_manifest_row_mal
                x_m_c = x_manifest_col_mal

                x_c_d = x_code_dat_mal
                x_c_r = x_code_row_mal
                x_c_c = x_code_col_mal
                
                xi = x_i_m
                
            else:
                x_m_d = x_manifest_dat
                x_m_r = x_manifest_row
                x_m_c = x_manifest_col

                x_c_d = x_code_dat
                x_c_r = x_code_row
                x_c_c = x_code_col
                
                xi = x_i
        else:
            idx = num #perm[num]
            
            x_m_d = x_manifest_dat
            x_m_r = x_manifest_row
            x_m_c = x_manifest_col
            
            x_c_d = x_code_dat
            x_c_r = x_code_row
            x_c_c = x_code_col
            
            xi = x_i
            
            y[idx] = 1 if isMalware else 0
            
        idx = xi['i']
        
        path = indir + '/' + sha256
        with open(path, 'r') as f:
            
            for line in f:
                try:
                    prefix = line[:line.index(":")]
                except ValueError:
                    #Ignore blank lines
                    continue
                    
                if prefix in manifest_prefix:
                    feat_idx = manifest_map[line]
                    x_m_i = xi['x_m']
                    x_m_d[x_m_i] = 1
                    x_m_r[x_m_i] = idx
                    x_m_c[x_m_i] = feat_idx
                    #print (line, idx, feat_idx)
                    xi['x_m'] = xi['x_m'] + 1
                else:
                    feat_idx = code_map[line]
                    x_c_i = xi['x_c']
                    x_c_d[x_c_i] = 1
                    x_c_r[x_c_i] = idx
                    x_c_c[x_c_i] = feat_idx
                    #print (line, idx, feat_idx)
                    xi['x_c'] = xi['x_c'] + 1
        
        num = num + 1
        xi['i'] = xi['i'] + 1

samples = num
        
x_manifest_dat = x_manifest_dat[:x_i['x_m']]
x_manifest_row = x_manifest_row[:x_i['x_m']]
x_manifest_col = x_manifest_col[:x_i['x_m']]

x_code_dat = x_code_dat[:x_i['x_c']]
x_code_row = x_code_row[:x_i['x_c']]
x_code_col = x_code_col[:x_i['x_c']]

x_manifest = csr_matrix((x_manifest_dat, (x_manifest_row, x_manifest_col)), shape=(samples, manifest_inputs))
x_code = csr_matrix((x_code_dat, (x_code_row, x_code_col)), shape=(samples, code_inputs))

        
if split:
    
    #Truncate numpy matrixes to correct length
    x_manifest_dat = x_manifest_dat_mal[:x_i_m['x_m']]
    x_manifest_row = x_manifest_row_mal[:x_i_m['x_m']]
    x_manifest_col = x_manifest_col_mal[:x_i_m['x_m']]

    #Truncate numpy matrixes to correct length
    x_code_dat = x_code_dat_mal[:x_i_m['x_c']]
    x_code_row = x_code_row_mal[:x_i_m['x_c']]
    x_code_col = x_code_col_mal[:x_i_m['x_c']]

    x_manifest_mal = csr_matrix((x_manifest_dat, (x_manifest_row, x_manifest_col)), shape=(num_mal, manifest_inputs))
    x_code_mal = csr_matrix((x_code_dat, (x_code_row, x_code_col)), shape=(num_mal, code_inputs))

    valid_good = int(samples/10)
    valid_mal = int(num_mal/10)

    train_good = samples - valid_good
    train_mal = num_mal - valid_mal

    x_test = [vstack((x_manifest[-valid_good:] , x_manifest_mal[-valid_mal:])),
              vstack((x_code[-valid_good:] , x_code_mal[-valid_mal:]))]

    y_test = np.zeros((valid_good+valid_mal,), dtype=np.int8) 
    y_test[:valid_good] = 0
    y_test[valid_good:] = 1
else:
    num_valid = samples / 10
    x_train = [x_manifest[:-num_valid], x_code[:-num_valid]]
    x_test = [x_manifest[-num_valid:], x_code[-num_valid:]]

    y_train = y[:-num_valid]
    y_test = y[-num_valid:]

import cPickle as pickle

#Save mapping from features to indexes. useful for figuring out what we were looking at
with open( processed_dir+"code_map.pickle", "wb" ) as f:
    pickle.dump( dict(code_map), f )

with open( processed_dir+"manifest_map.pickle", "wb" ) as f:
    pickle.dump( dict(manifest_map), f )


#Save hash orders
with open( processed_dir+"good_hashes.pickle", "wb" ) as f:
    pickle.dump( good_hashes, f )

with open( processed_dir+"mal_hashes.pickle", "wb" ) as f:
    pickle.dump( mal_hashes, f )

#Save training date
with open( processed_dir+"x_manifest.pickle", "wb" ) as f:
    pickle.dump( x_manifest, f )

with open( processed_dir+"x_manifest_mal.pickle", "wb" ) as f:
    pickle.dump( x_manifest_mal, f )

with open( processed_dir+"x_code.pickle", "wb" ) as f:
    pickle.dump( x_code, f )

with open( processed_dir+"x_code_mal.pickle", "wb" ) as f:
    pickle.dump( x_code_mal, f )

#Save test data
with open( processed_dir+"x_test.pickle", "wb" ) as f:
    pickle.dump( x_test, f )

with open( processed_dir+"y_test.pickle", "wb" ) as f:
    pickle.dump( y_test, f )
